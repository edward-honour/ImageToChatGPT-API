{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq05EXHRiiho/sDu0PzV15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edward-honour/ImageToChatGPT-API/blob/main/ImageRecognitionOpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Install Required Libraries**\n",
        "\n",
        "Pillow is a popular Python imaging library used to open, manipulate, and save image files. It's essentially the modern fork of the original PIL (Python Imaging Library), which is now outdated.\n",
        "\n",
        "OpenAI is the ChatGPT API."
      ],
      "metadata": {
        "id": "4C1bm3G9BeTB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J8Dhi7cHAXns"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet openai pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Import openai and userdata**"
      ],
      "metadata": {
        "id": "e_-JrAtUCGGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata    # to get API Key.\n",
        "import openai                        # to access ChatGPT\n",
        "\n",
        "from google.colab import files       # to upload and read a file\n",
        "from PIL import Image                # to work with images\n",
        "from IPython.display import display  # to display the image\n",
        "import io                            # input/output library\n",
        "import base64                        # convert to base64."
      ],
      "metadata": {
        "id": "tu15s3DFCEuF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Load your OpenAI API key (from Google Colab)**"
      ],
      "metadata": {
        "id": "cUv7b3JiB3Lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jY7lRdD4B0m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = userdata.get('OpenAI')"
      ],
      "metadata": {
        "id": "baPoJGSqCCPO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Upload File**"
      ],
      "metadata": {
        "id": "tutjU8uTC4Uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "iCw1TeI7C-JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Open the Image**"
      ],
      "metadata": {
        "id": "ed957Y1JC-8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = next(iter(uploaded))\n",
        "image = Image.open(image_path)\n",
        "display(image)"
      ],
      "metadata": {
        "id": "mqq_5x17DI2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Function to encode image**"
      ],
      "metadata": {
        "id": "3k-rwChjDik_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image_to_base64(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n"
      ],
      "metadata": {
        "id": "FIn5d8OnDoIX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 7: Perform the Base Encode**"
      ],
      "metadata": {
        "id": "vsvYjnThDqcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_base64 = encode_image_to_base64(image_path)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HVEZi72-EgyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 8: Call ChatGPT**"
      ],
      "metadata": {
        "id": "OY_f_02MEk7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # GPT-4o is the only model that supports images\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"Identify the objects in this image.\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}},\n",
        "            ],\n",
        "        }\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "R5-AXh-ZD6LP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "kFnmx284EgBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}